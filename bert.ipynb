{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python Implementations and Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Hey everyone! Today, we'll be going over some more specific examples of common Python applications. Meaning, we'll dive deeper into some more useful and technical packages supported by Python. Just a brief caveat: there may be parts of this talk that are overly technical, or just may not be relevant to you. That's okay. I think it's important to go over examples of more technical Python use-cases, so we have a greater perspective about what Python can be used for. And, as long as you have some Python knowledge, or programming experience, I feel it's okay if you're feeling a little lost at certain parts of this talk, since I essentially divided this talk into segments.\n",
    "\n",
    "<br />\n",
    "\n",
    "In the beginning stages of this talk, we'll implement our own NLP model. Specifically, we'll implement a sentiment classifier using a pre-trained neural network called BERT. This model will allow us to make very accurate predictions about the sentiment of movie reviews, which will hopefully be somewhat fun for some of you.\n",
    "\n",
    "<br />\n",
    "\n",
    "After implementing our model, we'll demonstrate how we can write some of the important output of our model, such as testing examples, to a database using Python. This will hopefully be cool for us to see how Python can be useful to not only data scientists, but data engineers as well, and how they can all work together.\n",
    "\n",
    "<br />\n",
    "\n",
    "Lastly, we'll move into some back-end engineering tasks, like setting up an actual web service using Python. More specifically, we'll want to make our sentiment classifier available to other people for testing purposes. So, we'll use a Python package, called Flask, to create a way for other people access our Python classifier on the web.\n",
    "\n",
    "<br />\n",
    "\n",
    "And, we'll also want to create an actual front-end for users to interact with our sentiment classifier web service. So, we'll use another Python package to create an interface, along with some stylish visualizations, so users can play around with it.\n",
    "\n",
    "<br />\n",
    "\n",
    "But, for now, let's just focus on building a pretty simple NLP model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introducing NLP Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Before we go any further into model building, let me actually just take a few moments to help motivate sentiment analysis and NLP tasks as a whole.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### History of NLP\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Before we go any further into model building, let me actually just take a few moments to help motivate sentiment analysis and NLP tasks as a whole. First, let's start off with a quick history lesson of how NLP has developed over the last decade or so.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Lots of progress in NLP over the last decade!\n",
    "- CBOW\n",
    "    - Used in early stages of NLP\n",
    "    - Advantage: Predicts the next word in a sentence\n",
    "    - Disadvantage: Limited to fixed sentences\n",
    "    - Disadvantage: Excludes relationships in a sentence\n",
    "- ELMo\n",
    "    - Created at the start of 2018\n",
    "    - Advantage: Predicts the next word in a sentence, and more!\n",
    "    - Advantage: Captures relationships in a sentence\n",
    "    - Disadvantage: Harder to capture relationships in longer sentences\n",
    "- BERT\n",
    "    - Created at the end of 2018\n",
    "    - Advantage: Predicts the next word in a sentence, and more!\n",
    "    - Advantage: Captures relationships in a sentence, even in longer sentences!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "So, let me just start off by saying there's been a lot of progress in NLP over the last decade. Going back to the early 2000s, a guy named Bengio proposed the first neural language model using a neural network, where machine translation was fairly expensive and somewhat hard to solve. At that time, statistical models, such as the continuous bag-of-words model, were used to solve fairly simple NLP tasks, such as next-word prediction and spell checking. This model was useful for predicting next words in sentences, but lacked the ability to pick up on the context of words in sentences, or really understand any of the relationships between words.\n",
    "\n",
    "<br />\n",
    "\n",
    "Then, starting at around 2010, many more complex NLP problems were beginning to be solved. For one, Apple's Siri became known as one of the worldâ€™s first successful NLP assistants to be used by general consumers. So, problems like question and answering and chat bots were beginning to be solved. And, these types of NLP models were beginning to be able to pick up on the context of words in sentences. But, these tasks were still fairly expensive and slow. Plus, it was still somewhat difficult to understand the relationships between words for longer sentences.\n",
    "\n",
    "<br />\n",
    "\n",
    "Then, in the last decade, companies like Google, Facebook, Apple, and others, were able to build more complex neural network architectures, which allowed them to solve more complex NLP problems. And, they were able to capture relationships in very long sentences fairly well. Google, for example, trained a network called BERT, which was able to solve some of these problems very well. Other networks have since been released by other companies, but they really pioneered this movement towards using sequence networks for NLP tasks, which allowed companies to easily create chat bots, summarize text, perform auto-completion, translate text from one language to another, and so much more.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Applications for BERT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Next-sentence prediction\n",
    "- Multi-task language modeling\n",
    "- Text classification\n",
    "- Question answering\n",
    "- Sentiment analysis\n",
    "- So much more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Yeah, so here, I just want to list some of the applications for BERT. I've only listed a few, like next-sentence prediction, multi-task language modeling, text classification, question answering, and sentiment analysis. But, just know, there are so many more applications solved by NLP networks like BERT and other similar networks, like GPT3.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Motivating NLP Tasks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now that we've briefly discussed the history and development of some of these important NLP applications, let me quickly touch on how NLP models differ from a lot of generic classification models, including image classification models, that have existed for a while.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- NLP models have the following properties:\n",
    "    - Designed for handling sequential data\n",
    "    - Can allow multiple outputs\n",
    "- Most NLP data is messy\n",
    "- Most NLP data preprocessing is cumbersome\n",
    "- Training accurate NLP models is slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Specifically, NLP models usually are designed for handling sequential data, since most NLP problems only use some series of words as input, where these words represent some sequential series of words in most cases. Also, NLP models can receive a single input or multiple inputs, and they can output a single value or multiple values. In most generic classification models, including image classification models, they only really allow a single output to be spit out.\n",
    "\n",
    "<br />\n",
    "\n",
    "Also, a staple of most NLP models is that the data is fairly messy and needs a fair amount of data preprocessing. The training can be very slow as well, compared to simpler, more generic classification models.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is BERT?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now that we've introduced the use of neural networks to solve some of the more complex NLP problems, let's briefly motivate the reason for using BERT in particular for some of these NLP problems, and sentiment analysis in particular.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- BERT is a pre-trained Transformer model\n",
    "- Pre-trained on:\n",
    "    - English Wikipedia (2500M words)\n",
    "    - BookCorpus (800M words)\n",
    "- Achieved the best accuracies for NLP tasks in 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Well, for starters, BERT is a pre-trained transformer model. So, over the last decade, Google has spent billions of dollars researching ways of solving some of these complex NLP problems, and developing a neural architecture to do this efficiently. As I mentioned earlier, they were able to do this in 2018 when they created BERT. Generously, they open-sourced this model to the public. Meaning, anyone could use their state of the art model for free.\n",
    "\n",
    "<br />\n",
    "\n",
    "And, just to be clear, this wasn't just another NLP model. This was a very robust and accurate model that could be applied to many different NLP tasks. It was also trained on a huge amount of data, that would have been very difficult for any other person or company to process. Specifically, the model learned from all of the English words from Wikipedia, which consisted of 2500M words. On top of that, it also learned from a a dataset consisting of 800M words, which came from published and unpublished books.\n",
    "\n",
    "<br />\n",
    "\n",
    "As a result, it was able to achieve the best accuracies for so many NLP tasks when it was released in 2018, such as sentiment analysis, text summarization, and many more. Since then, many other companies and researchers have made their own version of BERT by slightly tweaking their model, such as GPT3 and the T5 model. Some of these models produce even better accuracies as well. However, most of these models have very comparable accuracies to BERT for many NLP tasks. And, some of these models I mentioned haven't even been fully released yet. So, for now, we'll focus on implementing BERT.\n",
    "\n",
    "<br />\n",
    "\n",
    "Even though there are some slightly improved models out there, we'll use BERT to build our own sentiment classifier. I'll also show you how you can improve BERT to learn more refined tasks, such as classifying sentiments for a particular topic, such as movie reviews. Let me move on so I can explain this in more detail.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predicting Sentiment of Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now that I've motivated the importance of some of the most major NLP problems seen at various companies, let's go back to actually implementing the BERT model, and specifically building a model that predicts the sentiment of IMDB movie reviews, which will hopefully be fun for us.\n",
    "\n",
    "<br />\n",
    "\n",
    "Before we can start building a model, let's first load in the data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loading IMDB Movie Reviews\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Here, we're just loading in some packages used for reading in the csv consisting of 50k IMDB reviews. We're also reading in the BERT model that we'll use for predicting the sentiment of a given review, which we'll go over later on.\n",
    "\n",
    "<br />\n",
    "\n",
    "Now, let's read in the actual take and take a look at it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./imdb.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now, we're actually reading in our reviews scraped from IMDB's site. This data includes two columns: a review column including the actual text of the review, and a sentiment column including a String representing the sentiment of the review.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reformatting the Data for BERT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  One of the other reviewers has mentioned that ...      1\n",
       "1  A wonderful little production. <br /><br />The...      1\n",
       "2  I thought this was a wonderful way to spend ti...      1\n",
       "3  Basically there's a family where a little boy ...      0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = (df['sentiment']=='positive').astype(int)\n",
    "df.columns = ['text', 'label']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Before inputting our data into the BERT model, we'll need to reformat our columns so the input is only numeric data, since the BERT model doesn't understand Strings or any text data.\n",
    "\n",
    "<br />\n",
    "\n",
    "So, we're just assigning 1 to the *positive* labels, and we're assigning 0 to the *negative* labels. Then, we'll rename our columns to make them slightly more readable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prepare for BERT Training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 40000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_valid = train_test_split(df, test_size=0.2)\n",
    "len(df), len(df_train), len(df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Before I go any further into the specifics of model training, let me just make sure we all know why we want to train BERT or any other neural network. As a I said earlier, BERT was built to be used for many different NLP tasks, such as predicting next sentences, topic classification, sentiment classification, and many more NLP tasks. More technically, BERT was built for making predictions about sequential data, which many NLP tasks are. So, BERT is useful for us here, because we're interested in sentiment analysis.\n",
    "\n",
    "<br />\n",
    "\n",
    "Now, why do we want to train our network on more data, if BERT learned from millions and millions of sentences by Google for various NLP tasks already. Well, it's because BERT was trained on a lot of general data, so in order for us to get more accurate predictions, we need to fine tune our model to focus more on movie reviews, rather than make predictions on all Wikipedia data. Basically, BERT provides a great start for a lot of NLP tasks, but we will usually still need to fine tune it.\n",
    "\n",
    "<br />\n",
    "    \n",
    "Now, normally when we want to train any model, we'll split our data into a training set and test set. The training set will be used for the model to actually learn from our training data, and the test set will be used for us to validate the accuracy of our model after training. The training set is usually somewhere between 70-90% of our entire dataset. For now, we'll just assign the size of our test set to be 20% of our total movie reviews.\n",
    "\n",
    "<br />\n",
    "\n",
    "Notice, when we print out the lengths of each dataset, the training set has 40K reviews, and our test set has 10K reviews.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'num_train_epochs': 3,\n",
    "    'learning_rate': 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Another thing we usually do before training our model is assigning some hyperparameters that are relevant to our model. These can be modified if we train our model multiple times to see which one gives us a better accuracy. It's best practice to save these hyperparameters and their resulting accuracies after we train our model with different hyperparameter settings.\n",
    "\n",
    "<br />\n",
    "\n",
    "Let's not worry to much about this step, but just know that the number of training epochs, learning rate, and many other hyperparameters can be set and help improve the accuracy of our model if we play around with these values.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training the BERT Model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel('bert', 'bert-large-cased', args=hyperparameters, use_cuda=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now, in a single line, we're actually loading in the BERT model. Again, just in a single line, we're able to basically load in a very accurate model used by Google for so many NLP features internally and on their site. Notice, we're loading in our hyperparameter specifications as well. This *ClassificationModel* function can use many other NLP model for different classification tasks, such as GPT and many others.\n",
    "\n",
    "<br />\n",
    "\n",
    "So, the *bert* argument specifies that we want to use the BERT model for classification, rather than GPT or some other NLP model for classification. Then, the *bert-large-cased* is a tokenizer, that basically converts every single word from our reviews into a number. They basically have a vocabulary behind-the-scenes that performs a 1-to-1 mapping of a word in the vocabulary to some arbitrary number. We'll go into this a little deeper later.\n",
    "\n",
    "<br />\n",
    "\n",
    "There is also a *use_cuda* argument used for our function here, but just don't worry about this. Just know that we can specify other arguments in our function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.train_model(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Finally, we'll be able to train our model using the training data we split earlier. I'm not going to run this line of code now, because it would take hours to train our 40K lines of movie reviews to iterate until we get an extremely accurate model.\n",
    "\n",
    "<br />\n",
    "\n",
    "Luckily, I trained on this data before our talk. So, I'll just import the model I trained earlier, then we can start actually making predictions using our trained model. So, let me quickly import it now, so we don't have to just wait here for a few hours.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/bert-imdb\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"lvwerra/bert-imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Here, we're just loading in the model I trained earlier, which I had named *bert-imdb*. Along with it, we're loading in the pre-trained tokenizer I mentioned earlier, which just maps the words in reviews to some fixed number.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Predicting Sentiment with BERT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test = 'i love this movie'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now that we've done the more complicated stuff associated to model building and model training, let's actually get to the fun part, which is testing the accuracy of our model when we send in some new inputs our model hasn't seen before.\n",
    "\n",
    "<br />\n",
    "\n",
    "Here, let's say we're interested in seeing how our model classifies a review that simply says *i love this movie*. This is a very simple example, but in a little bit, I'll show you how our model can do pretty well against more complicated examples that you guys come up with. For now, we'll assign our review to a variable called *test*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101,  178, 1567, 1142, 2523,  102]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = tokenizer.encode(test, return_tensors=\"pt\")\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Again, our BERT model can only understand numeric data. So, we'll just quickly tokenize our input data. Notice, our review contains 4 words, but the output of our tokenizer contains 6 tokens. At first you might think this is a mistake, but it's actually just a great example of how complex and smart our pre-trained tokenizer is. This tokenizer basically looks at some text, and doesn't just map individual words to a number. But, it actually maps parts of words Google deemed was important in understanding the context behind these sentences. So, 101 might refer to the word *I*, then 178 might refer to the word *love*, or 178 might refer to the first two letters of *love*: *lo*. We can take a closer look at the internals of what these numbers are actually mapped too, but unfortunately we'd need to look at the internals of the tokenizer object. So, for now, just take my word for it.\n",
    "\n",
    "<br />\n",
    "\n",
    "Anyways, all we're doing here is converting our review from a series of words to a series of mapped numbers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.6446,  4.2778]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.forward(test_tensor)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now, once we've converted our review to some numbers, we can finally see what our model thinks about the sentiment of this very basic review. To do this, we just call the *forward* function on our model, and we'll receive some output, including something called the loss, logits, and some other details. We're only interested in the logits here, so we're going to extract the logits from this output.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interpreting BERT Output\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6446,  4.2778]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = outputs.logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "So, that's all we're doing here. We're just grabbing the logits from the output. And, logits are basically just inputs of a softmax function in tensorflow. Meaning, they're some values we need in order to calculate the probabilities of the review being positive or negative.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3.6240346e-04, 9.9963760e-01], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = tf.nn.softmax(logits[0].detach())\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now, let's go ahead and input these into our softmax function, which will spit out these probabilities. I'm going to do one more step so that these probabilities are in a more readible format.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00036240346"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_neg = probs[0].numpy()\n",
    "prob_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996376"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_pos = probs[1].numpy()\n",
    "prob_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "All I'm doing in this last step is reformatting these probabilities. Notice, our model is extremely certain that this review is positive, and not negative at all. Specifically, it's saying there's a 99% chance that this review is positive, which I think we can all agree that it is.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Saving our Predictions to a Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now that we've succesfully implemented our pretty cool NLP model, let me briefly show you how to save a some of these predictions in a database. In most cases, we may be interested in saving our testing cases in a database, along with the predicted sentiments for those reviews. We'd also most likely be interested in saving any hyperparameters when we tweak our model in the future. By doing this, we'll be able to compare the accuracies from our tweaked models, and officially land on the best model for predicting movie reviews.\n",
    "\n",
    "<br />\n",
    "\n",
    "For this example, I previously set up a really simple PostgreSQL database so we can save our predictions somewhere. We can just think of our PostgreSQL database as any other relational SQL database. It's not really important for us to understand why I selected a PostgreSQL database here. The important thing for us to understand is that we can save our predictions to any database using Python.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loading Sentiments in Database\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "As usual, first thing we'll want to do is load in the appropriate Python packages for interacting with PostgreSQL databases. Here, we'll just need to import a fairly well-known package called SQLAlchemy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "db_string = 'postgres://postgres:6300FitchP(@localhost:5432/postgres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "db = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Next, we'll want to initialize a connection with our database. To do this, we'll first create a String consisting of important components relative to our database. Specifically, we'll specify the type of database, and in this case we'll specify postgresql. We'll also want to specify a username and password. And, we'll also want to specify our host URL and the port running our PostgreSQL server. Lastly, we'll specify the database we'll want our table to live in.\n",
    "\n",
    "<br />\n",
    "\n",
    "Then, we'll run a simple function called *create_engine* that we loaded in from SQLAlchemy. This will just initialize a connection with our database so we can create tables and write entries in our database.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Writing Sentiments into Database\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now that we're all set up and connected to our PostgreSQL database, let's actually write some predictions to it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x1a51e25450>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute(\"CREATE TABLE IF NOT EXISTS reviews (review_id SERIAL PRIMARY KEY, review VARCHAR(200) NOT NULL, sentiment DECIMAL NOT NULL)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "First, we'll need to create a table in our database. By running this SQL command, we can create a table called *reviews*. I also specified some other details about our table, like the columns included in our table. Specifically, our table consists of three columns: a review_id column, review column, and a sentiment column. This review_id is just an index number associated with our row. The review is the actual review we decide to run through our model. And, the sentiment column is just the probability of our review being positive. I also included some other details about these columns, like specifying a primary key, but just ignore these details for now. They're not very important to us.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x1af3430090>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_sql = \"INSERT INTO reviews (review_id, review, sentiment) VALUES (1, '{0}', {1})\".format(test, prob_pos)\n",
    "db.execute(review_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now, let's finally just insert our previous review we made up: *I love this movie*. Again, the sentiment associated with this review was about 99%, so we should expect to see this sentiment in our database. And, in a single line of code, we can insert an entirely new row into our database, including the review and sentiment.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'i love this movie', Decimal('0.9996376037597656'))\n"
     ]
    }
   ],
   "source": [
    "reviews = db.execute('SELECT * FROM reviews')\n",
    "for r in reviews:  \n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Lastly, let's just print out the rows in our database by running a SELECT * statement. Obviously, we'll only have one row in our database, but let's just get a quick look at the format. As expected, we'll see the row id number is *1*, the review is *i love this movie*, and its sentiment is about 99%.\n",
    "\n",
    "<br />\n",
    "\n",
    "This is pretty cool and powerful, given we didn't need to add too much code just to write and save test results to a database in Python. But, just to make sure we understand how powerful this can be, let's just add another rows to our database for fun.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Another Movie Review\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "So, before we just add a review to our database, we'll need to calculate its sentiment. Just to show off how powerful our sentiment classifier is, I'll create a review that doesn't necessarily relate to movies. Specifically, let's just see what our model says about the sentiment of a review reading *i want some pizza*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x1af35d7cd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'i want some pizza'\n",
    "test_tensor = tokenizer.encode(test, return_tensors=\"pt\")\n",
    "outputs = model.forward(test_tensor)\n",
    "probs = tf.nn.softmax(outputs.logits[0].detach())\n",
    "prob_pos = probs[1].numpy()\n",
    "review_sql = \"INSERT INTO reviews (review_id, review, sentiment) VALUES (2, '{0}', {1})\".format(test, prob_pos)\n",
    "db.execute(review_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "There's quite a few lines here. But, note how much we're actually achieving here. In just a few lines of Python, we're able to run an entirely new review through our model, have our model classify the review, extract the sentiment, and save the sentiment in our database. I think that's pretty cool and powerful.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'i love this movie', Decimal('0.9996376037597656'))\n",
      "(2, 'i want some pizza', Decimal('0.9139239192008972'))\n"
     ]
    }
   ],
   "source": [
    "reviews = db.execute('SELECT * FROM reviews')\n",
    "for r in reviews:  \n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "So, we already wrote our second review to our database. Let's print out the rows again to see how our model classified our review. It looks like it actually did a pretty good job at predicting the movie review as a positive sentiment, even though it didn't really have anything to do with movies. We could continue to add movie reviews to our database, but I'll stop here for now.\n",
    "\n",
    "<br />\n",
    "\n",
    "Also, I should say our new database we set up is pretty powerful and can handle lots of sentiment predictions at a given time. Specifically, it can handle writing 10K-100K rows per second, which is pretty incredible. And notice, we could absolutely do this, since our sentiment classifier only took milliseconds to classify reviews.\n",
    "\n",
    "<br />\n",
    "\n",
    "Okay, so saving our movie reviews and their sentiments to a productionized database is obviously pretty cool and powerful. Especially, since we're most likely interested in using this information to improve our model in the future, and draw insights off of our tests once we gather enough of them. But now, let's try something a little different. Specifically, we'll create an actual web API. Once we do this, we can actually just send basic web requests through our browser to our web service, and then anyone in the world who has a browser and internet access will be able to send their own movie reviews through our classifier so they can find out how our model rates their review. And think about it. Not only can anyone use our sentiment classification model and input their own reviews, but we'll be able to also collect those reviews and the sentiments our model generates behind-the-scenes, then save them to our database. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Creating a Sentiment Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Building a Form\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "<form method=\"POST\">\n",
    "    <input name=\"text\">\n",
    "    <input type=\"submit\">\n",
    "</form>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Preparing the Service\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from flask import Flask, request, render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/bert-imdb\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"lvwerra/bert-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Building a URL Rule\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@app.route('/', methods=['GET'])\n",
    "def form():\n",
    "    return render_template('bertform.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@app.route('/', methods=['POST'])\n",
    "def predict():\n",
    "    review = request.form['text']\n",
    "    test_tensor = tokenizer.encode(review, return_tensors=\"pt\")\n",
    "    outputs = model.forward(test_tensor)\n",
    "    probs = tf.nn.softmax(outputs.logits[0].detach())\n",
    "    prob_pos = probs[1].numpy()\n",
    "    return render_template('bertform.html') + '<b>Review:</b> {} <br /> <b>Sentiment:</b> {}'.format(review, str(prob_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "bert_flask.py contains the python code for the web service, while bertform.html contains the html code for the reproducible form.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Creating a Sentiment Web Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- plotly visualizations\n",
    "- dash front-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### References\n",
    "\n",
    "---\n",
    "\n",
    "- [History of NLP](https://www.dataversity.net/a-brief-history-of-natural-language-processing-nlp/)\n",
    "- [Training BERT](https://lvwerra.github.io/trl/03-bert-imdb-training/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
